{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8287c6",
   "metadata": {},
   "source": [
    "# **AI TECH INSTITUTE** ¬∑ *Intermediate AI & Data Science*\n",
    "### Week 01 ¬∑ Notebook 03 ‚Äî Data Wrangling & Transformation\n",
    "**Instructor:** Amir Charkhi  |  **Goal:** Master real-world data manipulation techniques.\n",
    "\n",
    "> Format: practical scenarios ‚Üí powerful pandas methods ‚Üí data ready for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35e8bb",
   "metadata": {},
   "source": [
    "---\n",
    "## Real Data is Messy!\n",
    "Let's load and clean actual messy data - the skills you'll use every day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da6e4326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to wrangle! üõ†Ô∏è\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set display options for better visibility\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "print(\"Ready to wrangle! üõ†Ô∏è\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f40a1",
   "metadata": {},
   "source": [
    "## 1. Reading Data from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0037003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data from CSV:\n",
      "   order_id  customer_name   product  quantity   price order_date\n",
      "0      1001    Alice Smith    Laptop         1  1200.0 2025-08-15\n",
      "1      1002      Bob Jones     Mouse         2    25.5 2025-08-15\n",
      "2      1003  Charlie Brown       NaN         1    80.0 2025-08-16\n",
      "3      1004    Alice Smith   Monitor         1     NaN 2025-08-16\n",
      "4      1005   Diana Prince  Keyboard         3    75.0 2025-08-17\n",
      "5      1006            NaN    Webcam         1   120.0 2025-08-17\n",
      "6      1007      Bob Jones    Laptop         1  1200.0 2025-08-18\n",
      "\n",
      "Data types:\n",
      "order_id                  int64\n",
      "customer_name            object\n",
      "product                  object\n",
      "quantity                  int64\n",
      "price                   float64\n",
      "order_date       datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "order_id         0\n",
      "customer_name    1\n",
      "product          1\n",
      "quantity         0\n",
      "price            1\n",
      "order_date       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create sample CSV data (simulating a file)\n",
    "csv_data = \"\"\"order_id,customer_name,product,quantity,price,order_date\n",
    "1001,Alice Smith,Laptop,1,1200.00,2025-08-15\n",
    "1002,Bob Jones,Mouse,2,25.50,2025-08-15\n",
    "1003,Charlie Brown,,1,80.00,2025-08-16\n",
    "1004,Alice Smith,Monitor,1,,2025-08-16\n",
    "1005,Diana Prince,Keyboard,3,75.00,2025-08-17\n",
    "1006,,Webcam,1,120.00,2025-08-17\n",
    "1007,Bob Jones,Laptop,1,1200,2025-08-18\"\"\"\n",
    "\n",
    "# Save to file and read back\n",
    "with open('orders.csv', 'w') as f:\n",
    "    f.write(csv_data)\n",
    "\n",
    "# Read CSV with proper data types\n",
    "orders_df = pd.read_csv('orders.csv', parse_dates=['order_date'])\n",
    "print(\"Raw data from CSV:\")\n",
    "print(orders_df)\n",
    "print(f\"\\nData types:\")\n",
    "print(orders_df.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(orders_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741c1c71",
   "metadata": {},
   "source": [
    "## 2. Cleaning Missing and Incorrect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "127850d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data:\n",
      "   order_id     customer_name   product  quantity   price order_date   total\n",
      "0      1001       Alice Smith    Laptop         1  1200.0 2025-08-15  1200.0\n",
      "1      1002         Bob Jones     Mouse         2    25.5 2025-08-15    51.0\n",
      "2      1003     Charlie Brown  Keyboard         1    80.0 2025-08-16    80.0\n",
      "3      1004       Alice Smith   Monitor         1   350.0 2025-08-16   350.0\n",
      "4      1005      Diana Prince  Keyboard         3    75.0 2025-08-17   225.0\n",
      "5      1006  Unknown Customer    Webcam         1   120.0 2025-08-17   120.0\n",
      "6      1007         Bob Jones    Laptop         1  1200.0 2025-08-18  1200.0\n",
      "\n",
      "Revenue by customer:\n",
      "customer_name\n",
      "Alice Smith         1550.0\n",
      "Bob Jones           1251.0\n",
      "Diana Prince         225.0\n",
      "Unknown Customer     120.0\n",
      "Charlie Brown         80.0\n",
      "Name: total, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bduong\\AppData\\Local\\Temp\\ipykernel_11112\\2590105866.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  clean_df['customer_name'].fillna('Unknown Customer', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Make a copy for cleaning\n",
    "clean_df = orders_df.copy()\n",
    "\n",
    "# Handle missing customer names\n",
    "clean_df['customer_name'].fillna('Unknown Customer', inplace=True)\n",
    "\n",
    "# Handle missing products (look at other orders from same customer)\n",
    "clean_df.loc[2, 'product'] = 'Keyboard'  # Reasonable guess based on price\n",
    "\n",
    "# Handle missing prices (use average for that product)\n",
    "monitor_avg_price = 350.00  # Domain knowledge\n",
    "clean_df.loc[3, 'price'] = monitor_avg_price\n",
    "\n",
    "# Ensure price is float\n",
    "clean_df['price'] = pd.to_numeric(clean_df['price'], errors='coerce')\n",
    "\n",
    "# Calculate total\n",
    "clean_df['total'] = clean_df['quantity'] * clean_df['price']\n",
    "\n",
    "print(\"Cleaned data:\")\n",
    "print(clean_df)\n",
    "print(f\"\\nRevenue by customer:\")\n",
    "print(clean_df.groupby('customer_name')['total'].sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e6510a-22dd-4931-87af-89b2111d69a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id         1.000000\n",
       "customer_name    0.857143\n",
       "product          0.857143\n",
       "quantity         1.000000\n",
       "price            0.857143\n",
       "order_date       1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_df.notnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4131ecd-8fe4-4071-b227-a66debe3a09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id\n",
      "quantity\n",
      "price\n"
     ]
    }
   ],
   "source": [
    "for col in orders_df.select_dtypes(include='number'):\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265e60a",
   "metadata": {},
   "source": [
    "**Exercise 1 ‚Äî Data Quality Check (medium)**  \n",
    "Create a function that returns a data quality report: % complete, unique counts, and outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582c78e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Complete</th>\n",
       "      <th>Unique Count</th>\n",
       "      <th>Outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_name</th>\n",
       "      <td>85.714286</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>85.714286</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantity</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>85.714286</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_date</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               % Complete  Unique Count  Outliers\n",
       "order_id       100.000000             7       0.0\n",
       "customer_name   85.714286             4       NaN\n",
       "product         85.714286             5       NaN\n",
       "quantity       100.000000             3       1.0\n",
       "price           85.714286             5       0.0\n",
       "order_date     100.000000             4       NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your turn\n",
    "def quality_check(df):\n",
    "    report = pd.DataFrame(index=df.columns)\n",
    "    \n",
    "    # % Complete\n",
    "    report['% Complete'] = df.notnull().mean() * 100\n",
    "    \n",
    "    # Unique Counts\n",
    "    report['Unique Count'] = df.nunique()\n",
    "    \n",
    "    # Outliers (using IQR method)\n",
    "    outlier_counts = {}\n",
    "    for col in df.select_dtypes(include='number'):\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = ((df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)).sum()\n",
    "        outlier_counts[col] = outliers\n",
    "    report['Outliers'] = pd.Series(outlier_counts)\n",
    "    \n",
    "    return report\n",
    "\n",
    "quality_check(orders_df)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f25302",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "def data_quality_report(df):\n",
    "    report = {}\n",
    "    \n",
    "    # Completeness\n",
    "    report['completeness'] = (1 - df.isnull().sum() / len(df)) * 100\n",
    "    \n",
    "    # Unique counts\n",
    "    report['unique_counts'] = df.nunique()\n",
    "    \n",
    "    # Outliers for numeric columns (using IQR)\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    outliers = {}\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers[col] = ((df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)).sum()\n",
    "    report['outliers'] = outliers\n",
    "    \n",
    "    return report\n",
    "\n",
    "quality_report = data_quality_report(clean_df)\n",
    "print(\"Data Quality Report:\")\n",
    "for key, value in quality_report.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(value)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd91af14",
   "metadata": {},
   "source": [
    "## 3. Merging and Joining DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b93cc6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers:\n",
      "   customer_id           name       city member_since\n",
      "0            1    Alice Smith      Perth   2023-01-15\n",
      "1            2      Bob Jones     Sydney   2023-06-20\n",
      "2            3  Charlie Brown  Melbourne   2024-02-10\n",
      "3            4   Diana Prince   Brisbane   2024-08-01\n",
      "\n",
      "Orders:\n",
      "   order_id  customer_id  amount       date\n",
      "0       101            1     150 2025-08-20\n",
      "1       102            2     250 2025-08-21\n",
      "2       103            1     100 2025-08-22\n",
      "3       104            3     300 2025-08-23\n",
      "4       105            1     175 2025-08-24\n",
      "\n",
      "Merged data:\n",
      "   order_id  customer_id  amount       date           name       city  \\\n",
      "0       101            1     150 2025-08-20    Alice Smith      Perth   \n",
      "1       102            2     250 2025-08-21      Bob Jones     Sydney   \n",
      "2       103            1     100 2025-08-22    Alice Smith      Perth   \n",
      "3       104            3     300 2025-08-23  Charlie Brown  Melbourne   \n",
      "4       105            1     175 2025-08-24    Alice Smith      Perth   \n",
      "\n",
      "  member_since  \n",
      "0   2023-01-15  \n",
      "1   2023-06-20  \n",
      "2   2023-01-15  \n",
      "3   2024-02-10  \n",
      "4   2023-01-15  \n",
      "\n",
      "Inner join (only matching):\n",
      "Rows: 5\n",
      "\n",
      "Outer join (all records):\n",
      "   order_id  customer_id  amount       date           name       city  \\\n",
      "0     101.0            1   150.0 2025-08-20    Alice Smith      Perth   \n",
      "1     103.0            1   100.0 2025-08-22    Alice Smith      Perth   \n",
      "2     105.0            1   175.0 2025-08-24    Alice Smith      Perth   \n",
      "3     102.0            2   250.0 2025-08-21      Bob Jones     Sydney   \n",
      "4     104.0            3   300.0 2025-08-23  Charlie Brown  Melbourne   \n",
      "5       NaN            4     NaN        NaT   Diana Prince   Brisbane   \n",
      "\n",
      "  member_since      _merge  \n",
      "0   2023-01-15        both  \n",
      "1   2023-01-15        both  \n",
      "2   2023-01-15        both  \n",
      "3   2023-06-20        both  \n",
      "4   2024-02-10        both  \n",
      "5   2024-08-01  right_only  \n"
     ]
    }
   ],
   "source": [
    "# Create related dataframes\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4],\n",
    "    'name': ['Alice Smith', 'Bob Jones', 'Charlie Brown', 'Diana Prince'],\n",
    "    'city': ['Perth', 'Sydney', 'Melbourne', 'Brisbane'],\n",
    "    'member_since': ['2023-01-15', '2023-06-20', '2024-02-10', '2024-08-01']\n",
    "})\n",
    "\n",
    "orders = pd.DataFrame({\n",
    "    'order_id': [101, 102, 103, 104, 105],\n",
    "    'customer_id': [1, 2, 1, 3, 1],\n",
    "    'amount': [150, 250, 100, 300, 175],\n",
    "    'date': pd.date_range('2025-08-20', periods=5)\n",
    "})\n",
    "\n",
    "print(\"Customers:\")\n",
    "print(customers)\n",
    "print(\"\\nOrders:\")\n",
    "print(orders)\n",
    "\n",
    "# Merge dataframes\n",
    "merged = pd.merge(orders, customers, on='customer_id', how='left')\n",
    "print(\"\\nMerged data:\")\n",
    "print(merged)\n",
    "\n",
    "# Different join types\n",
    "print(\"\\nInner join (only matching):\")\n",
    "inner_join = pd.merge(orders, customers, on='customer_id', how='inner')\n",
    "print(f\"Rows: {len(inner_join)}\")\n",
    "\n",
    "print(\"\\nOuter join (all records):\")\n",
    "outer_join = pd.merge(orders, customers, on='customer_id', how='outer', indicator=True)\n",
    "print(outer_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac1848",
   "metadata": {},
   "source": [
    "## 4. Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddf3b8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales data:\n",
      "        date    store product  quantity  revenue\n",
      "0 2025-08-01  Store_C  Laptop         5     1995\n",
      "1 2025-08-02  Store_A  Laptop         3     1511\n",
      "2 2025-08-03  Store_C   Phone         7     1125\n",
      "3 2025-08-04  Store_C   Phone         5     1121\n",
      "4 2025-08-05  Store_A  Laptop         9     1513\n",
      "5 2025-08-06  Store_A  Laptop         7      665\n",
      "6 2025-08-07  Store_C  Laptop         2     1229\n",
      "7 2025-08-08  Store_B  Tablet         4     1895\n",
      "8 2025-08-09  Store_C  Tablet         9     1945\n",
      "9 2025-08-10  Store_C  Tablet         2     1600\n",
      "\n",
      "Store summary:\n",
      "        quantity revenue                   \n",
      "             sum     sum         mean count\n",
      "store                                      \n",
      "Store_A       29    4819   963.800000     5\n",
      "Store_B       21    6521  1086.833333     6\n",
      "Store_C       48   11997  1333.000000     9\n",
      "\n",
      "Revenue by product and store:\n",
      "store    Store_A  Store_B  Store_C\n",
      "product                           \n",
      "Laptop      3689     1986     3224\n",
      "Phone       1130        0     4727\n",
      "Tablet         0     4535     4046\n",
      "\n",
      "Average revenue by day:\n",
      "day_of_week\n",
      "Friday       1383.67\n",
      "Monday        764.00\n",
      "Saturday     1252.33\n",
      "Sunday       1273.33\n",
      "Thursday     1454.00\n",
      "Tuesday      1333.33\n",
      "Wednesday     803.00\n",
      "Name: revenue, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create sales data\n",
    "np.random.seed(42)\n",
    "sales = pd.DataFrame({\n",
    "    'date': pd.date_range('2025-08-01', periods=20),\n",
    "    'store': np.random.choice(['Store_A', 'Store_B', 'Store_C'], 20),\n",
    "    'product': np.random.choice(['Laptop', 'Phone', 'Tablet'], 20),\n",
    "    'quantity': np.random.randint(1, 10, 20),\n",
    "    'revenue': np.random.randint(100, 2000, 20)\n",
    "})\n",
    "\n",
    "print(\"Sales data:\")\n",
    "print(sales.head(10))\n",
    "\n",
    "# Group by store\n",
    "store_summary = sales.groupby('store').agg({\n",
    "    'quantity': 'sum',\n",
    "    'revenue': ['sum', 'mean', 'count']\n",
    "})\n",
    "print(\"\\nStore summary:\")\n",
    "print(store_summary)\n",
    "\n",
    "# Multiple grouping\n",
    "product_store = sales.groupby(['product', 'store'])['revenue'].sum().unstack(fill_value=0)\n",
    "print(\"\\nRevenue by product and store:\")\n",
    "print(product_store)\n",
    "\n",
    "# Add calculated columns\n",
    "sales['revenue_per_unit'] = sales['revenue'] / sales['quantity']\n",
    "sales['day_of_week'] = sales['date'].dt.day_name()\n",
    "\n",
    "# Group by day of week\n",
    "daily_pattern = sales.groupby('day_of_week')['revenue'].mean().round(2)\n",
    "print(\"\\nAverage revenue by day:\")\n",
    "print(daily_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c85c5e",
   "metadata": {},
   "source": [
    "**Exercise 2 ‚Äî Customer Segmentation (hard)**  \n",
    "Group customers by total spend into segments: VIP (>500), Regular (200-500), New (<200).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "877407e0-cbc3-41c4-bc37-fa86c850b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['amount'] = np.where(merged['order_id'] == 101, 300,\n",
    "                            np.where(merged[\"order_id\"] == 102, 150, merged[\"amount\"])\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "17f39466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>member_since</th>\n",
       "      <th>Customer_Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>2025-08-20</td>\n",
       "      <td>Alice Smith</td>\n",
       "      <td>Perth</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>VIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>2025-08-21</td>\n",
       "      <td>Bob Jones</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>2023-06-20</td>\n",
       "      <td>New</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2025-08-22</td>\n",
       "      <td>Alice Smith</td>\n",
       "      <td>Perth</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>VIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>Charlie Brown</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>Alice Smith</td>\n",
       "      <td>Perth</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>VIP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  customer_id  amount       date           name       city  \\\n",
       "0       101            1     300 2025-08-20    Alice Smith      Perth   \n",
       "1       102            2     150 2025-08-21      Bob Jones     Sydney   \n",
       "2       103            1     100 2025-08-22    Alice Smith      Perth   \n",
       "3       104            3     300 2025-08-23  Charlie Brown  Melbourne   \n",
       "4       105            1     175 2025-08-24    Alice Smith      Perth   \n",
       "\n",
       "  member_since Customer_Segment  \n",
       "0   2023-01-15              VIP  \n",
       "1   2023-06-20              New  \n",
       "2   2023-01-15              VIP  \n",
       "3   2024-02-10          Regular  \n",
       "4   2023-01-15              VIP  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your turn\n",
    "\n",
    "#Define Condition\n",
    "total_spend = merged.groupby(\"customer_id\")[\"amount\"].sum()\n",
    "customer_segment = total_spend.apply(lambda x : \"VIP\" if x > 500 else \"Regular\" if 200 <= x <= 500 else \"New\")\n",
    "customer_segment = customer_segment.reset_index()\n",
    "customer_segment.rename(columns={'amount': 'Customer_Segment'}, inplace=True)\n",
    "\n",
    "\n",
    "merged = pd.merge(merged, customer_segment, on='customer_id', how='left')\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdbd6b9",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Calculate customer totals\n",
    "customer_totals = merged.groupby('name')['amount'].sum().reset_index()\n",
    "customer_totals.columns = ['customer', 'total_spend']\n",
    "\n",
    "# Create segments\n",
    "def segment_customer(spend):\n",
    "    if spend > 500: return 'VIP'\n",
    "    elif spend >= 200: return 'Regular'\n",
    "    else: return 'New'\n",
    "\n",
    "customer_totals['segment'] = customer_totals['total_spend'].apply(segment_customer)\n",
    "\n",
    "print(\"Customer segments:\")\n",
    "print(customer_totals.sort_values('total_spend', ascending=False))\n",
    "\n",
    "# Segment summary\n",
    "print(\"\\nSegment distribution:\")\n",
    "print(customer_totals['segment'].value_counts())\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f3255a",
   "metadata": {},
   "source": [
    "## 5. Pivoting and Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a54870cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long format:\n",
      "         date  metric  value\n",
      "0  2025-08-01   Sales   4342\n",
      "1  2025-08-02   Costs   1455\n",
      "2  2025-08-03  Profit   4533\n",
      "3  2025-08-04   Sales   4798\n",
      "4  2025-08-05   Costs   2275\n",
      "..        ...     ...    ...\n",
      "7  2025-08-08   Costs   3343\n",
      "8  2025-08-09  Profit   4796\n",
      "9  2025-08-10   Sales   3767\n",
      "10 2025-08-11   Costs   4820\n",
      "11 2025-08-12  Profit   1337\n",
      "\n",
      "[12 rows x 3 columns]\n",
      "\n",
      "Wide format (pivoted):\n",
      "metric       Costs  Profit   Sales\n",
      "date                              \n",
      "2025-08-01     NaN     NaN  4342.0\n",
      "2025-08-02  1455.0     NaN     NaN\n",
      "2025-08-03     NaN  4533.0     NaN\n",
      "2025-08-04     NaN     NaN  4798.0\n",
      "2025-08-05  2275.0     NaN     NaN\n",
      "\n",
      "Melted back to long:\n",
      "        date metric  amount\n",
      "0 2025-08-01  Costs     NaN\n",
      "1 2025-08-02  Costs  1455.0\n",
      "2 2025-08-03  Costs     NaN\n",
      "3 2025-08-04  Costs     NaN\n",
      "4 2025-08-05  Costs  2275.0\n",
      "\n",
      "Pivot table with totals:\n",
      "product  Laptop  Phone  Tablet    All\n",
      "store                                \n",
      "Store_A    3689   1130       0   4819\n",
      "Store_B    1986      0    4535   6521\n",
      "Store_C    3224   4727    4046  11997\n",
      "All        8899   5857    8581  23337\n"
     ]
    }
   ],
   "source": [
    "# Create long format data\n",
    "long_data = pd.DataFrame({\n",
    "    'date': pd.date_range('2025-08-01', periods=12),\n",
    "    'metric': ['Sales', 'Costs', 'Profit'] * 4,\n",
    "    'value': np.random.randint(1000, 5000, 12)\n",
    "})\n",
    "\n",
    "print(\"Long format:\")\n",
    "print(long_data)\n",
    "\n",
    "# Pivot to wide format\n",
    "wide_data = long_data.pivot(index='date', columns='metric', values='value')\n",
    "print(\"\\nWide format (pivoted):\")\n",
    "print(wide_data.head())\n",
    "\n",
    "# Melt back to long format\n",
    "melted = wide_data.reset_index().melt(id_vars='date', var_name='metric', value_name='amount')\n",
    "print(\"\\nMelted back to long:\")\n",
    "print(melted.head())\n",
    "\n",
    "# Pivot table with aggregation\n",
    "pivot_table = sales.pivot_table(\n",
    "    values='revenue',\n",
    "    index='store',\n",
    "    columns='product',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0,\n",
    "    margins=True\n",
    ")\n",
    "print(\"\\nPivot table with totals:\")\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93813ac",
   "metadata": {},
   "source": [
    "## 6. String Operations and Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f70e311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messy contact data:\n",
      "              name                 email           phone\n",
      "0     john smith    John.Smith@GMAIL.com    0412-345-678\n",
      "1         JANE DOE      jane@company.COM  (04) 9876 5432\n",
      "2  Bob Johnson Jr.          bob@email.co      0401234567\n",
      "3       alice wong       Alice@Email.net    04 1111 2222\n",
      "\n",
      "Cleaned contacts:\n",
      "        name_clean           email_clean phone_clean       domain\n",
      "0       John Smith  john.smith@gmail.com  0412345678    gmail.com\n",
      "1         Jane Doe      jane@company.com  0498765432  company.com\n",
      "2  Bob Johnson Jr.          bob@email.co  0401234567     email.co\n",
      "3       Alice Wong       alice@email.net  0411112222    email.net\n"
     ]
    }
   ],
   "source": [
    "# Create messy text data\n",
    "contacts = pd.DataFrame({\n",
    "    'name': ['  john smith  ', 'JANE DOE', 'Bob Johnson Jr.', 'alice wong'],\n",
    "    'email': ['John.Smith@GMAIL.com', 'jane@company.COM', 'bob@email.co', 'Alice@Email.net'],\n",
    "    'phone': ['0412-345-678', '(04) 9876 5432', '0401234567', '04 1111 2222']\n",
    "})\n",
    "\n",
    "print(\"Messy contact data:\")\n",
    "print(contacts)\n",
    "\n",
    "# Clean strings\n",
    "contacts['name_clean'] = contacts['name'].str.strip().str.title()\n",
    "contacts['email_clean'] = contacts['email'].str.lower()\n",
    "\n",
    "# Extract domain from email\n",
    "contacts['domain'] = contacts['email_clean'].str.split('@').str[1]\n",
    "\n",
    "# Standardize phone numbers\n",
    "contacts['phone_clean'] = contacts['phone'].str.replace(r'[^0-9]', '', regex=True)\n",
    "\n",
    "print(\"\\nCleaned contacts:\")\n",
    "print(contacts[['name_clean', 'email_clean', 'phone_clean', 'domain']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de98963a",
   "metadata": {},
   "source": [
    "## 7. Date and Time Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b7b1b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series with date components:\n",
      "        date        sales  year  month day_of_week  week\n",
      "0 2025-01-01  1878.000000  2025      1   Wednesday     1\n",
      "1 2025-01-02  2179.955845  2025      1    Thursday     1\n",
      "2 2025-01-03  1994.368322  2025      1      Friday     1\n",
      "3 2025-01-04  5286.892626  2025      1    Saturday     1\n",
      "4 2025-01-05  3635.572413  2025      1      Sunday     1\n",
      "\n",
      "Weekly aggregation:\n",
      "                   mean           sum          std\n",
      "date                                              \n",
      "2025-01-05  2994.957841  14974.789206  1464.270684\n",
      "2025-01-12  2915.168033  20406.176228  1020.068936\n",
      "2025-01-19  3410.428571  23873.000000  1661.414047\n",
      "2025-01-26  2641.689110  18491.823772   751.721868\n",
      "2025-02-02  2416.076423  16912.534961  1346.988050\n",
      "\n",
      "With rolling statistics:\n",
      "         date        sales  rolling_mean_7d  rolling_std_7d\n",
      "95 2025-04-06  3155.012702      3218.549437     1284.359723\n",
      "96 2025-04-07  4789.528258      3311.618595     1381.988316\n",
      "97 2025-04-08  4654.260948      3756.513016     1206.778698\n",
      "98 2025-04-09  3316.260948      3921.270888     1016.716142\n",
      "99 2025-04-10  4100.528258      3967.722307     1016.367042\n"
     ]
    }
   ],
   "source": [
    "# Create time series data\n",
    "dates = pd.date_range('2025-01-01', periods=100, freq='D')\n",
    "ts_data = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'sales': np.random.randint(1000, 5000, 100) + np.sin(np.arange(100) * 2 * np.pi / 30) * 500\n",
    "})\n",
    "\n",
    "# Extract date components\n",
    "ts_data['year'] = ts_data['date'].dt.year\n",
    "ts_data['month'] = ts_data['date'].dt.month\n",
    "ts_data['day_of_week'] = ts_data['date'].dt.day_name()\n",
    "ts_data['week'] = ts_data['date'].dt.isocalendar().week\n",
    "\n",
    "print(\"Time series with date components:\")\n",
    "print(ts_data.head())\n",
    "\n",
    "# Resample to weekly\n",
    "weekly = ts_data.set_index('date')['sales'].resample('W').agg(['mean', 'sum', 'std'])\n",
    "print(\"\\nWeekly aggregation:\")\n",
    "print(weekly.head())\n",
    "\n",
    "# Rolling window calculations\n",
    "ts_data['rolling_mean_7d'] = ts_data['sales'].rolling(window=7).mean()\n",
    "ts_data['rolling_std_7d'] = ts_data['sales'].rolling(window=7).std()\n",
    "\n",
    "print(\"\\nWith rolling statistics:\")\n",
    "print(ts_data[['date', 'sales', 'rolling_mean_7d', 'rolling_std_7d']].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cecfa82",
   "metadata": {},
   "source": [
    "**Exercise 3 ‚Äî Time Series Analysis (hard)**  \n",
    "Find the best and worst performing days of the week, and calculate week-over-week growth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2a14e6bb-28bb-4a56-a3db-deeebd7103f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Worst day is:\n",
      "  day_of_week        sales\n",
      "0      Friday  2670.760938\n",
      "\n",
      "Best day is:\n",
      "  day_of_week        sales\n",
      "4    Thursday  3535.875155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0           NaN\n",
       "1     36.270207\n",
       "2     16.989091\n",
       "3    -22.540846\n",
       "4     -8.540471\n",
       "        ...    \n",
       "10    18.692099\n",
       "11   -28.403543\n",
       "12    18.741359\n",
       "13     8.997257\n",
       "14   -25.163366\n",
       "Name: sales, Length: 15, dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sales = ts_data.groupby('day_of_week')['sales'].mean().reset_index()\n",
    "worst_day = avg_sales[avg_sales['sales'] == avg_sales['sales'].min()]\n",
    "best_day =  avg_sales[avg_sales['sales'] == avg_sales['sales'].max()]\n",
    "print(\"\\nWorst day is:\")\n",
    "print(worst_day)\n",
    "print(\"\\nBest day is:\")\n",
    "print(best_day)\n",
    "weekly_sales = ts_data.groupby('week')['sales'].sum().reset_index()\n",
    "test['sales'].pct_change() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a2e9d0",
   "metadata": {},
   "source": [
    "## 8. Mini-Challenges\n",
    "- **M1 (easy):** Create a function to detect duplicate rows based on subset of columns\n",
    "- **M2 (medium):** Implement a data validation function that checks data types and ranges\n",
    "- **M3 (hard):** Create a pipeline that cleans, transforms, and aggregates raw sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aba28e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn - try the challenges!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d4790",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Solutions</b></summary>\n",
    "\n",
    "```python\n",
    "# M1 - Duplicate detection\n",
    "def find_duplicates(df, subset=None):\n",
    "    duplicates = df[df.duplicated(subset=subset, keep=False)]\n",
    "    return duplicates.sort_values(subset if subset else df.columns.tolist())\n",
    "\n",
    "# M2 - Data validation\n",
    "def validate_data(df, rules):\n",
    "    \"\"\"\n",
    "    rules = {\n",
    "        'column_name': {'type': str, 'min': 0, 'max': 100, 'required': True}\n",
    "    }\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "    for col, rule in rules.items():\n",
    "        if col not in df.columns and rule.get('required'):\n",
    "            issues.append(f\"Missing required column: {col}\")\n",
    "            continue\n",
    "        \n",
    "        if 'type' in rule:\n",
    "            wrong_type = df[col].apply(lambda x: not isinstance(x, rule['type']))\n",
    "            if wrong_type.any():\n",
    "                issues.append(f\"{col}: {wrong_type.sum()} type mismatches\")\n",
    "        \n",
    "        if 'min' in rule:\n",
    "            below_min = df[col] < rule['min']\n",
    "            if below_min.any():\n",
    "                issues.append(f\"{col}: {below_min.sum()} values below {rule['min']}\")\n",
    "    \n",
    "    return issues\n",
    "\n",
    "# M3 - Data pipeline\n",
    "def sales_pipeline(raw_df):\n",
    "    # Clean\n",
    "    df = raw_df.copy()\n",
    "    df = df.dropna(subset=['product', 'revenue'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Transform\n",
    "    df['month'] = df['date'].dt.to_period('M')\n",
    "    df['revenue_category'] = pd.cut(df['revenue'], \n",
    "                                     bins=[0, 500, 1000, float('inf')],\n",
    "                                     labels=['Low', 'Medium', 'High'])\n",
    "    \n",
    "    # Aggregate\n",
    "    summary = df.groupby(['month', 'product']).agg({\n",
    "        'revenue': ['sum', 'mean', 'count'],\n",
    "        'quantity': 'sum'\n",
    "    }).round(2)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Test pipeline\n",
    "result = sales_pipeline(sales)\n",
    "print(\"Pipeline output:\")\n",
    "print(result.head())\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7840780f",
   "metadata": {},
   "source": [
    "## Wrap-Up\n",
    "‚úÖ You can read and clean messy real-world data  \n",
    "‚úÖ You mastered merging, grouping, and pivoting  \n",
    "‚úÖ You can handle dates, strings, and missing values  \n",
    "\n",
    "**Next:** EDA - Exploring and understanding your cleaned data!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
